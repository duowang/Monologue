name,monologue
John Oliver,"Last Week Tonight with John Oliver Season 12 Episode 2 Aired on February 23, 2025"
John Oliver,John Oliver discusses Facebook’s controversial new plans for content moderation and which Animorphs he would and would not kill with his car.
John Oliver,"Our main story tonight concerns technology—the thing that’s brought us stone tools, the catapults, the Tamagotchi, and one day, God willing, a fourth thing worth having."
John Oliver,"One of the biggest stories from the last election is just how much the tech industry seemed to swing toward Trump. Elon Musk, of course, campaigned and jumped for him, and Jeff Bezos reportedly killed the Washington Post endorsement of Kamala Harris and got a prime seat at the inauguration alongside the CEOs of both Google and Apple. But one of the most visible swings came from Mark Zuckerberg. He famously banned Trump from Facebook after January 6th, but last month he was co-hosting a party at his inauguration. And just two weeks before, he made this striking announcement:"
John Oliver,"Oh, is that what you wanted to talk about? Because honestly I’d much rather discuss why you suddenly look like Eddie Redmayne was cast to play Ice Cube. You look like White Macklemore. You look like a high schooler going undercover as a different high schooler with fewer friends. But I’m sorry—you were talking about getting back to your roots."
John Oliver,"Yeah, that is the CEO of Meta announcing that he’s getting rid of fact-checkers, and saying that he doesn’t want to be out of touch with mainstream discourse while wearing a $900,000 watch. There’s just no way any watch is worth that much, unless when you look at it, it reads: “It’s time to donate the rest of your money. You officially seem to have too much."
John Oliver,"The changes Zuckerberg’s making are striking. A leaked training document found it’s now acceptable to say immigrants are “grubby filthy pieces of shit,” and also specifies that this slur for trans people is no longer a designated slur and is therefore allowed. As for replacing fact-checkers with Community Notes like on X, it is worth noting that hasn’t been a raging success over there, with one study finding nearly three quarters of accurate Community Notes on election misinformation never got shown to users. Remember that tweet falsely claiming Haitians were eating pets in Springfield, Ohio? That claim was rated PolitiFact’s lie of the year—but there is still no Community Note on the tweet, despite multiple attempts to add one."
John Oliver,"And all of this is a pretty notable shift for Zuckerberg—because seven years ago, amid widespread public outcry around Facebook stoking misinformation and hatred, he went before Congress to apologize:"
John Oliver,"Yeah. It seems that Victorian ghost has made a pretty big turnaround since—both in terms of what he’s saying and how he looks. And I will admit: New Zuck does look like he’s having more fun. He’s tan. He looks like he’s shopping at stores that only take crypto, and he’s not sitting in front of Congress looking like a depressed version of the guy from the “stonks” meme."
John Oliver,Zuckerberg is framing all of this as merely responding to a broader cultural shift—something that he outlined naturally on Joe Rogan:
John Oliver,"Is there anything more off-putting than a guy worth hundreds of billions trying to be a relatable everyman? You know how it is—chilling in the living room with the bros, cracking a six-pack of Ace of Spades Magnums, kicking back on your diamond-encrusted sofa, and turning on the big-screen TV, which in my house is a hollow box where I pay the cast of The Office to reenact my favorite scenes. You know—just relatable, everyday stuff, guys!"
John Oliver,"And look, I’m not saying Facebook was doing a perfect job of moderating content until now—we’ve criticized them multiple times before on this show. I’m also not saying they even could have done it perfectly. It’s been said that content moderation at scale is impossible to do well. But the decision to both abandon fact-checkers and turn off systems they previously claimed made the platform safer does feel like he’s about to make that site a whole lot worse. And the self-depiction of Zuckerberg—rap name Lil’ Broccoli—as someone simply embracing his company’s “roots around free expression” is just self-serving bullshit."
John Oliver,"So given all of that, tonight let’s take a look at the challenges of content moderation, how Facebook’s faced them in the past, and what might have led to its new approach. And let’s start with the challenges, because from the very beginning of the modern internet, there were concerns about what was on it."
John Oliver,"In 1995, Senator James Exon brought a blue binder to the floor of the Senate. It was full of—well—"
John Oliver,"The most hardcore, perverse types of pornography."
John Oliver,The images came from the internet. Exon wanted his fellow Senators to realize what kids could see:
John Oliver,Come by my desk. Take a look at this disgusting material.
John Oliver,"Okay, so there’s a lot to love there—from the binder that says “WARNING” in big letters, to the invitation to “come by his desk anytime for some disgusting material,” but my favorite part has to be the clip of a Playboy JPEG loading one centimeter at a time. That is an extremely accurate portrayal of what online porn was like in the ’90s. How do I know? No reason at all."
John Oliver,"Back then, there were battles in both Congress and the courts about how the law should treat websites’ hosting of things like pornography and defamatory comments. For a brief time, there were questions about whether a site’s decision to moderate content in any way made it a publisher, and therefore liable for anything that it didn’t remove."
John Oliver,"That ultimately led to the passage of what’s known as Section 230 —often described as “the 26 words that created the internet.” It stated the companies could be shielded from liability for what its users post, because unlike, say, a print publisher, websites are dealing with so much material they couldn’t possibly vet all of it. It does have some carve-outs—it doesn’t give sites a pass for certain types of illegal content, like child sexual abuse and terrorism materials—but mostly, it allows them to moderate without fear."
John Oliver,"Which is good—because as scholars will tell you, content moderation is absolutely key to making the internet bearable:"
John Oliver,You can’t have a usable platform if you don’t do some sort of content moderation—otherwise every platform will just be porn and diet pills.
John Oliver,"Right. That would be a problem, especially on a website like, say, LinkedIn. Although, to be honest, it might already be just porn and diet pills—I haven’t been on it in years, as I’ve had this job since 2014 and frankly have no interest in learning how other people rise and grind."
John Oliver,"The point is though, if you want people to use your site, and crucially, have companies want to pay to advertise on it, you’re going to have to make choices about what to remove—and how you make those choices is always going to be contentious."
John Oliver,"Facebook over the years has learned a lot of these lessons the hard way. In its early days, it took an almost touchingly naive approach, as this former employee explains:"
John Oliver,"We had to set up some ground rules—basic decency, no nudity, and no violent or hateful speech. And after that, we felt some reluctance to interpose our value system on this worldwide community that was growing."
John Oliver,"Was there not a concern then that it could become sort of a place of just utter confusion? That you have lies that are given the same weight as truths, and that it kind of just becomes a place where truth becomes completely obfuscated?"
John Oliver,No. We relied on what we thought were the public’s common sense and common decency to police the site.
John Oliver,"Oh, you did, did you? I mean, I’d say that was adorable, but frankly I would be embarrassed to go on Frontline and confess that everyone working at Facebook shared a level of wide-eyed naïveté that can only be described as full-blown Amelia Bedelia."
John Oliver,"Now, obviously, that initial optimism didn’t last, and over the years Facebook started implementing more and more rules and employing more and more people to enforce them. And that could be a grim job. Here is one moderator describing what it was like to screen thousands of disturbing images a day—with, I’m going to warn you, a very distracting disguise:"
John Oliver,"I think it would be easier to deal with the images if you weren’t having to think about them so deeply. I worked the evening shift, so I would start at 6:00 p.m., finish at 2:00 in the morning. But then you would often wake up three, four hours later. You’d suddenly sit up in bed remembering the decision that you’ve made and realizing that you’ve made a mistake—like, I’ve missed a nipple. You remember some image that you’ve seen, and you suddenly realized that there was a naked girl on one side or—or an ISIS flag in the background, so now it should have been deleted under the terrorism policy."
John Oliver,"Now, setting aside that it’s coming from a grown man with a baby head, talking like Darth Vader while dressed for vacation—that is a depressing glimpse into what Facebook was dealing with, and it’s just a long way from relying on the inherent good of humanity to hiring people to mainline ISIS porn."
John Oliver,"And while some decisions around blocking content were easy, others turned out to be more difficult. Because think about it: Say you ban nudity. What about statues? What about breastfeeding? What about a breastfeeding statue? And before you answer—what if I told you that I meant this one?"
John Oliver,"The company also had to develop policies around hate speech and misinformation—where the boundaries could be even trickier to define. For instance, their rules prohibited attacks on people because they belong to protected categories based on things like race, sex, gender identity, or religious affiliation. But it allowed users broader latitude when they wrote about narrower subsets of the categories."
John Oliver,"And watching moderators try to apply rules like that in practice can be bizarre, as this hidden-camera footage from a content moderation center in Ireland shows:"
John Oliver,"That ticket there—’fuck off back to your own country,’ and it says Muslim—Oh, immigrants—"
John Oliver,"If it just said ‘Muslims,’ then yeah you’d take this action. But it doesn’t, it’s actually an ignore."
John Oliver,He looks after stinking Muslim immigrants. I think that’s fine.
John Oliver,"Yeah, because saying that they’re stinking might be physical inferiority. If it said like Muslim immigrant scum, for example, that would be a delete."
John Oliver,"Yeah, that is a weird place to draw the line. But at the same time, anywhere you draw a line can be weird. Deciding where speech becomes harmful is like trying to figure out which of the horrifying nightmares on an Animorphs cover you wouldn’t run over with your car."
John Oliver,These freaks? No question. It’s on sight. I’ll bounce them off the front bumper of my Subaru going 80 and feel nothing.
John Oliver,"On the other end, though: Whoa, whoa, whoa—that’s a normal kid. Slow down. I’m not trying to do time."
John Oliver,"But in the middle? Yeah, that’s a question, isn’t it? That’s a question."
John Oliver,"And the thing is, the same goes with fact-checking. Obvious lies are one thing, but there are plenty of statements that are factually true but still technically misleading. And at one time, Facebook put a lot of thought into this—even producing this video in 2018, featuring a bunch of employees wrestling with the nuances of moderation, and one even diagramming out the problem as he saw it:"
John Oliver,"Imagine, on the X-axis, that you have the amount of truth in a piece of content. Now, on the Y-axis, you have the intent to mislead. You can take this chart and you can split it into four quadrants, right? On the bottom left, you have the set of things that are low-truth, but nobody was intending to mislead anything— that’s just called being wrong on the internet, and it happens. And in the bottom right, you know, it’s the set of things that have high truth—but again, nobody was trying to mislead anyone. That’s just called being right on the internet, and I’m sure it’ll happen someday. The top right—this is things that are high truth, high intent to mislead. So this is stuff like propaganda; this is stuff like cherry-picking of statistics. Now mind you, we have to be really careful here, right? Because of our commitment to free speech, everything we do here has to be incredibly, incredibly careful. But then we move to this quadrant—this is like the really dangerous quadrant, right? Low amount of truth, high intent to mislead. These are things that were explicitly designed and architected to be viral. These are the hoaxes of the world. These are things like Pizzagate. This is just false news. We have to get this right if we’re going to regain people’s trust."
John Oliver,"You know, it is amazing that all of this started when a young man had a simple dream of ranking his classmates by fuckability—and 15 years later, a company’s struggling to stop people from accusing random pizzerias of human trafficking. A butterfly masturbates in its dorm room, and it causes a hurricane for the rest of us."
John Oliver,"And to give that man credit, he’s genuinely wrestling with the issue there. But the company wasn’t doing that out of the goodness of its heart. Facebook had come under heavy fire for allowing fake news and hate speech to proliferate—not just in the U.S., but also abroad. We’ve talked before about how misinformation on Facebook helped fuel ethnic hatred, leading to headlines like “Facebook admits it was used to incite violence in Myanmar."
John Oliver,"It was around this time that Zuckerberg apologized to Congress, and the company began deploying an array of options to handle misinformation—from partnering with outside fact-checkers, to appending notes to posts. It would also delete some posts or limit the reach of others. And in doing so, it found itself constantly making very hard decisions under pressure from some very powerful people. Here is one such case—and a former Facebook employee explaining the decision they ended up making:"
John Oliver,We want to give this president the opportunity to do something historic.
John Oliver,This was the video of then-House Speaker Pelosi posted to Facebook in 2019—slowed down to make it seem that she was slurring her words.
John Oliver,Because it didn’t violate the policies that they had.
John Oliver,So did she put pressure on the company to take it down?
John Oliver,She was definitely not pleased. She definitely wanted the company—yes. And it really damaged the relationship that the company had with her.
John Oliver,Okay—set aside the fact that I don’t see why you need to slow down footage to embarrass Nancy Pelosi—a person who says plenty of embarrassing things at normal speed—I do kind of agree with Facebook there that “Does this piss off Nancy Pelosi?” isn’t a valid metric for taking that particular video down.
John Oliver,"And look, I’m not saying Facebook made the right decision 100% of the time. Again, no company operating at this scale could. But it did develop systems that it claimed worked pretty well. At one point, they bragged that when people saw fact-checkers had labeled content false or partially false, they would not click on it nearly 95% of the time. In a recent report, they noted that when it comes to hate speech they take action against, their systems automatically dealt with 95.3% of it—meaning users only had to report the rest."
John Oliver,"Now, of course, some of those tools are being watered down—and others are being turned off completely. And that brings us to the question of why. Why are they suddenly doing this?"
John Oliver,"Well, there are a few things that happened during the past 5 years that have helped bring us to this point. One has been conservatives repeatedly painting normal content moderation as political persecution:"
John Oliver,Big tech’s out to get conservatives. That’s not a suspicion—that’s not a hunch—that’s a fact.
John Oliver,"We’ve seen these, uh, these—big tech has been censoring us."
John Oliver,The American people are being censored. Conservatives are being censored. The information that’s flowing to the American people is being censored. It’s just the bottom line.
John Oliver,"Okay, that is obviously all bullshit."
John Oliver,"But to be fair, Devin Nunes knows a thing or two about censorship—given he once filed a $250 million lawsuit against Twitter accounts that made fun of him, including one that pretended to be Nunes’s cow. He sued a fake Twitter cow because it said mean things about him, prompting the ACLU to issue this actual statement headlined:"
John Oliver,Devin Nunes’s cow has a First Amendment right to call Representative Nunes a treasonous cowpoke.
John Oliver,We truly live in the single stupidest timeline.
John Oliver,"The point is, conservatives have been crying censorship for years—but the evidence for that is very weak. First, to the extent that posts do get flagged more, that’s probably because conservatives tend to be more likely to spread political misinformation—according to numerous empirical studies. But even if you think platforms are trying to suppress conservatives, they’re doing a terrible job of that, given many of Facebook’s top performers lean right, and there are three times as many explicitly conservative news influencers as liberal ones on the site."
John Oliver,"Nevertheless, Republicans conducted an all-out assault on the idea of content moderation, often citing one go-to example outlined here by Jeanine Pirro:"
John Oliver,"Who suppressed free speech in the 2020 election? Facebook, when they wouldn’t allow people to communicate, and the press to communicate, on Hunter Biden’s laptop."
John Oliver,"Right—Hunter Biden’s fucking laptop. A story that Big Tech successfully censored, which is why you’ve never heard about it. And I’m afraid it is worth taking a second to remind you of the details in this story—because while people’s minds might immediately swing to “Russian hoax” or “damning evidence of Biden corruption,” the truth is it was neither."
John Oliver,"Now, it eventually came out that files from the laptop were legit—but also that nothing on it revealed illegal or unethical behavior by Joe Biden."
John Oliver,So was initially suppressing the laptop story a fuck-up by these companies in hindsight? Yeah.
John Oliver,Was the story itself particularly revelatory or important? Not really.
John Oliver,"Did Facebook’s actions prevent people from finding out about it before the election? Again—not really. Even during the period Facebook was limiting its spread, the story got 54 million views on its site. So if this was an attempt at censorship, it was successful in limiting the audience to around the same number of people that watched the fucking Friends finale."
John Oliver,"But that initial decision meant Mark Zuckerberg got yelled at a lot by the right. And around that same time, he was also being yelled at by Biden’s White House—because as the COVID vaccine was rolling out, a lot of misinformation was circulating on Facebook. Biden himself said at one point of Facebook: “They’re killing people,” and while he quickly walked that back, to hear Zuckerberg tell it, the pressure from the White House to suppress anything critical of vaccines back then was overwhelming."
John Oliver,"Okay, he’s clearly pandering to Joe Rogan and his audience there—although many seem too distracted by his outfit for that to work well, given comments under that video include “Bro dressed like undercover cop,” “I thought this was Lil Dicky,” and “Why is a 40-year-old billionaire dressed like my 25-year-old shrooms guy?"
John Oliver,But—but let’s deal with his implicit claim that the government launched investigations to punish Facebook for hosting anti-vaccine content. It is true that the government’s investigated Facebook a lot in recent years—but none of those investigations fit Zuckerberg’s narrative. Some—like an FTC antitrust lawsuit—were launched during the first Trump administration. Others—like the CFPB’s investigation of big tech payment systems—involved multiple other companies. And much of the scrutiny the company’s received in recent years was actually the result of a whistleblower releasing a cache of documents known as the Facebook Files.
John Oliver,"As for Zuckerberg’s complaint the government was cursing and screaming at Facebook—they are allowed to do that. When we call up government agencies to check a fact, they can tell us to eat shit—because cursing does not violate your rights. For more on that, check out the Constitution for Total Fucking Dumbasses . What they can’t do is force you to do something—and in that interview, Zuckerberg describes his response to government demands back then as:"
John Oliver,"I was just like—well, we’re not going to do that."
John Oliver,"And exactly! You said no! As was your right. And don’t take my word for this: Allegations like these have been adjudicated in court. When two Republican state AGs tried suing the government, claiming it pressured platforms—including Facebook—to censor their speech, they lost in a 6–3 Supreme Court decision written by Amy Coney Barrett, who noted the plaintiffs could not demonstrate that their content was restricted due to government pressure."
John Oliver,"And look—I can understand Zuckerberg’s feelings being hurt by the president saying his company’s killing people, and—and I can understand him being sick of being yelled at by Republicans for doing too much, and by Democrats for doing too little. On some level, I can even understand a business wanting to cozy up to whoever’s in the White House."
John Oliver,But there is one other factor here that does seem relevant to this discussion and feels important to mention:
John Oliver,"It’s a political evolution for Meta. Four years after Facebook suspended Mr. Trump’s account in the wake of January 6th, and just months after the president-elect accused Zuckerberg of plotting against him in 2020, calling for life in prison if Zuckerberg did it again—but after Mr. Trump’s win, Zuckerberg traveled to Mar-a-Lago, his company donated a million dollars to the Trump inaugural fund, and now close Trump ally and UFC head Dana White is joining Meta’s board."
John Oliver,"Meta, Facebook—I think they’ve come a long way."
John Oliver,Do you think he’s directly responding to the threats that you have made to him in the past?
John Oliver,"Yeah. Yeah, probably. Trump threatened Mark Zuckerberg with life in prison. Then Zuckerberg turned around, gave him money, hired one of his buddies, and changed the direction his company was going. It doesn’t take a genius to draw a conclusion there—and in fact, it didn’t take one."
John Oliver,And—and it didn’t stop there. Meta also recently paid $25 million to settle a bullshit lawsuit that Trump filed over being kicked off Facebook—despite many experts agreeing that was well within the company’s rights.
John Oliver,"And at this point, it does begin to feel like Trump is doing exactly what Zuckerberg accused the Biden administration of: leveraging the power of his office to pressure social media companies to bend to his will. And Zuckerberg seems to be complying."
John Oliver,"And he’ll insist these changes are not a result of being under political pressure—but either way, Facebook sure seems now set to become an absolute sewer of hatred and misinformation. Which, I know, sounds like a pretty good description of Facebook already—but we’re about to see what happens when they really stop trying."
John Oliver,"So what can we do? Well, there are some bad ideas out there. Both Democrats and Republicans have, in recent years, suggested ways to amend Section 230 so companies are more liable for what appears on websites—but I am yet to see a proposal that couldn’t be easily weaponized to enable political censorship."
John Oliver,"There are definitely options available to companies that advertise on Facebook. And I would argue they might want to seriously consider whether they want their ads next to these actual sample sentences Facebook says are now acceptable. Hey Disney, you want Olaf promoting Frozen 3 next to that shit? I don’t know, maybe you do."
John Oliver,"But for individuals, the options here are more limited. You could delete your Meta accounts—and you would not be alone in doing that. In January, Google searches for how to cancel and delete Facebook, Instagram, and Threads accounts increased by over 5,000%. And there are alternatives out there that don’t seem as desperate to fall in line with Trump. But I do get that if Facebook and Instagram are where your family and friends are, you may not be ready to take that step. Just remember to take whatever you read on those platforms with even more of a grain of salt than you did before."
John Oliver,"But there is one small way you can actually fuck with Meta, and that is by making yourselves a bit less valuable to them. Remember, advertising makes up 98% of Meta’s revenue, and a key component is them being able to offer companies the ability to micro-target you. Meta can do that because they track massive amounts of data about not just what you do on their sites but all across the internet—which is why they probably would not want me to tell you that you can change your settings so that Facebook and Instagram cannot profit as much from your data anymore."
John Oliver,"If you’d be interested in the step-by-step guide on how to do that, simply visit johnoliverwantsyourraterotica.com ."
John Oliver,"And in the meantime, if Facebook is going to continue to subject us to a steadily rising tide of slurs, hoaxes, and misinformation, the least it can do is tell us the actual truth in its messaging:"
John Oliver,"Here at Facebook, it’s time to get back to our roots around free expression."
John Oliver,"We’ve been 100% committed to making Facebook a safe and inclusive place for all people. Over the years, we’ve tried our best to prevent the site from becoming a frothing toilet of the worst humanity has to offer."
John Oliver,"It felt like our responsibility—because we made the toilet, and got super rich from it."
John Oliver,"But moderating billions of users is really hard. They say without it, the internet would just be porn and diet pills. God, I wish those were the only things we had to look out for. It’s porn, diet pills, hoaxes, slurs, death threats, gambling, crypto scams, those pictures of like a weirdly jacked grandpa that say “one trick to getting turbo shredded after 50″—oh, it’s a lot."
John Oliver,Which is why we’re so happy to announce our 2025 policy on content moderation:
John Oliver,"To be clear, all our previous issues remain. But by strategically pivoting to “fuck it,” we’ve found it’s now more of a you problem."
John Oliver,"It’s so nice not to have to keep all the nuances straight. Like, why “immigrants are shitty” is acceptable, but “immigrants are shit” isn’t."
John Oliver,"You sure? I think because—oh hang on, is the adjective or the object—what if they wrote, “Go back to your country, immigrant?"
John Oliver,"You know how your older relatives would say, “I got an email from a prince in Africa who will send me a million dollars if I give him my social security number,” and you had to be like, “No grandma, that’s fake”?"
John Oliver,"Well, now you just have to do that for all your relatives—for all news, forever."
John Oliver,"Besides, what is the worst that could happen?"
John Oliver,"We kind of sort of contributed to a genocide in Myanmar, remember?"
John Oliver,What are the odds another genocide could happen?
John Oliver,I have no idea. We fired the team that would know.
John Oliver,"I’m just glad my baby’s going to grow up in a world where he can use the slurs of his choice. Or her choice. Or their—oh, right, no, that’s right. It’s two. Facebook decided it is just the two now. Hear that?"
John Oliver,"And to those who say this is just us rolling over for President Trump in the hopes he won’t throw us all in prison, let me forcefully say: Nuh-uh."
John Oliver,Donald Trump doesn’t set a tone here—unless he said he did. Did he?
John Oliver,"Just know that whatever’s happening out there, we here at Facebook are recommitting to our core values—the same ones we’ve definitely always had: Freedom of expression, avoidance of responsibility, and ranking college girls by hotness."
John Oliver,"No, no, that’s too far back. Okay, never mind."
John Oliver,"Facebook—it’s like a town square. If your town was also full of Russian spies and bots, some teenagers disguised as adults, and some adults disguised as teenagers, getting together at all hours of the day or night to say whatever they want—including conspiracy theories, plus variations on “but the Nazis also had some good ideas."
John Oliver,And also now you are the mayor and police of your town square.
Main Segment,"Online content moderation, particularly for Facebook Other segment: —"
Zuckerberg,Hey everyone. I want to talk about something important today because it’s time to get back to our roots around free expression on Facebook and Instagram.
Zuckerberg,"First, we’re going to get rid of fact-checkers and replace them with community notes similar to X, starting in the U.S. Second, we’re going to simplify our content policies and get rid of a bunch of restrictions on topics like immigration and gender that are just out of touch with mainstream discourse. Third, we’re changing how we enforce our policies to reduce the mistakes that account for the vast majority of censorship on our platforms. We used to have filters that scanned for any policy violation; now we’re going to focus those filters on tackling illegal and high-severity violations. And for lower severity violations, we’re going to rely on someone reporting an issue before we take action."
Zuckerberg,"For most of our existence, we’ve focused on all the good that connecting people can do. But it’s clear now that we didn’t do enough to prevent these tools from being used for harm as well. And that goes for fake news, for foreign interference in elections, and hate speech, as well as developers and data privacy. We didn’t take a broad enough view of our responsibility. And that was a big mistake. And it was my mistake, and I’m sorry."
Zuckerberg,"What we do is we try to build a platform that gives people a voice. But there’s this wholesale generational shift in who are the people who are being listened to. I think it’s just like a wholesale shift in saying, ‘We just want different people who we actually trust. Um, who are actually going to, like, tell us the truth. And, like, not give us, like, the opinions that you’re supposed to say, but, like, the type of stuff that I would actually—like, when I’m sitting in my living room with my friends—like, the stuff that we know is true.'"
Zuckerberg,"I mean basically these people from the Biden Administration would call up our team and like scream at them and curse. I mean Biden when he was—he gave some statement at some point, I don’t know if it was a press conference or to some journalists—where he basically was like, ‘these guys are killing people.’ And—and um—and I don’t know—then like all these different agencies and branches of government basically just like started investigating and coming after our company. It was—it was brutal. It was brutal."
Very Briefly,"back in 2020, while Trump was president, social media sites got a warning from the FBI to look out for “hack and leak” operations before the election. Then, in October, the New York Post ran a story based on files from a laptop they claimed belonged to Hunter Biden—which had been given to them by Steve Bannon and Rudy Giuliani. Facebook and Twitter were wary of the story. Twitter briefly didn’t allow people to post links to it, and Facebook allowed the story to be seen and shared but limited the article’s reach—only to remove that restriction soon after."
